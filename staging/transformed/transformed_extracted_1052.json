{
  "job": {
    "title": "je",
    "industry": "job_industry",
    "description": "{\"@context\": \"http://schema.org\", \"@type\": \"JobPosting\", \"datePosted\": \"2021-07-20T05:54:46.000Z\", \"description\": \"***This position is not offering sponsorship at this time. Must be capable of working for any US employer***<br><br>Roles/Responsibilities (5 - 8 day to day candidate\\u2019s responsibilities)<br><ul> <li>6+ years of work experience in Bigdata technology and Kafka. </li> <li>Strong Communication, Articulation, Analytical Skills. </li> <li>Ability to handle multiple stakeholders including management</li> <li>Collaborating closely with business users and PMO to review requirements. </li> <li>Develop, recommend and discuss technical designs that meet those requirements.</li> <li>Analyzing, documenting, and performing system configuration and setup as well as integration and system testing.</li> <li>Troubleshooting issues with existing systems and resolve. Ability to work in team environment and client interfacing skills.</li> <li>Unix shell scripting Knowledge and basic idea about unix file system, file transfer protocol (ftp, sftp, ssh, scp etc). Knowledge on firewall, file encryption/decryption etc will be added advantage.</li> <li>Any programming skill such as python or java will be added advantage.</li> <li>Basic Knowledge on any one RDBMS such as Oracle or MySQL, some basic knowledge on data models, theoretical/working knowledge on dimension model and/or entity relationship model, normalization etc.</li> <li>Knowledge on job scheduling such as Cron job or any UI based scheduler.</li> <li>Production job monitoring in Tidal - Verify whether jobs are running as per schedule, are there any long running jobs, failed job, restart, are there any missing data from source, reaching out to source point of contact and publish SLA to downstream teams.</li> <li>Run jobs manually with increased memory parameters if required from Unix command line.</li> <li>Update Chalk page for production support with any job events(documentation) and action to be taken if the same job events occur in future.</li> <li>Shift Handover documentation to next person in support roster. </li> <li>Submit firewall tickets when additional nodes are added, validate them, submit Big data Admin tickets etc using Internal service tracker system to respective teams and follow up to get them resolved.</li> <li>Should be able to work on small enhancements to the existing production process which involves Unix Shell scripting, file handling, data copy from Dev to Prod, Data copy from external sources, encryption, decryption etc. </li> <li>Should be able to understand the existing Hadoop environment, framework to develop and deploy code for any new requirements. </li> <li>Should be able to understand data issues in Prod, analyze the root cause and provide solutions such as full data reload or missing data load within SLA.</li> <li>Good Communication and Interpersonal Skills.</li> <br></ul>Required Qualifications (5 - 8 bullet points on must have skills)<br><ul> <li>Experience with Lean / Agile development methodologies</li> <li>Strong Communication, Articulation, Analytical Skills</li> <li>Ability to handle multiple stakeholders including management</li> <li>Collaborating closely with business users and PMO to review requirements. </li> <li>Develop, recommend and discuss technical designs that meet those requirements.</li> <li>Analyzing, documenting, and performing system configuration and setup as well as integration and system testing.</li> <li>Troubleshooting issues with existing systems and resolve. Ability to work in team environment and client interfacing skills.</li> <br><br></ul>Employee Status : Full Time Employee<br><br>Shift : Day Job<br><br>Travel : No<br><br>Job Posting : Jul 19 2021<br><br><strong><u>About Cognizant<br><br></u></strong>Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.<br><br>Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.<br><br>Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.<br><br>If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.\", \"employmentType\": \"FULL_TIME\", \"hiringOrganization\": {\"@type\": \"Organization\", \"name\": \"Cognizant\", \"sameAs\": \"https://www.linkedin.com/company/cognizant\", \"logo\": \"https://media-exp1.licdn.com/dms/image/C4E0BAQEoboJe0-DUPg/company-logo_200_200/0/1625144835174?e=1634774400&v=beta&t=mI1A_2X4lsvXZrAKKKWNW-1Qm6b7RbV2pK73OzgJBDs\"}, \"identifier\": {\"@type\": \"PropertyValue\", \"name\": \"Cognizant\", \"value\": \"bbf4736bfa1e0be9e807216146ddf1a3\"}, \"image\": \"https://media-exp1.licdn.com/dms/image/C4E0BAQEoboJe0-DUPg/company-logo_100_100/0/1625144835174?e=1634774400&v=beta&t=UylyXm7hhV1fCUj_UapjMyt6AY6RgPyVrz2owrWJf44\", \"industry\": \"Information Technology and Services,Management Consulting\", \"jobLocation\": {\"@type\": \"Place\", \"address\": {\"@type\": \"PostalAddress\", \"addressCountry\": \"US\", \"addressLocality\": \"St Louis\", \"addressRegion\": \"MO\", \"postalCode\": \"63121\", \"streetAddress\": null}, \"latitude\": 38.635357, \"longitude\": -90.20099}, \"skills\": \"\", \"title\": \"Big Data Engineer (Kafka/Hive)\", \"validThrough\": \"2021-08-19T05:54:45.000Z\", \"educationRequirements\": {\"@type\": \"EducationalOccupationalCredential\", \"credentialCategory\": \"bachelor degree\"}, \"experienceRequirements\": {\"@type\": \"OccupationalExperienceRequirements\", \"monthsOfExperience\": 72}}",
    "employment_type": "job_employment_type",
    "date_posted": "job_date_posted"
  },
  "company": {
    "name": "company_name",
    "link": "company_linkedin_link"
  },
  "education": {
    "required_credential": "job_required_credential"
  },
  "experience": {
    "months_of_experience": "job_months_of_experience",
    "seniority_level": "seniority_level"
  },
  "salary": {
    "currency": "salary_currency",
    "min_value": "salary_min_value",
    "max_value": "salary_max_value",
    "unit": "salary_unit"
  },
  "location": {
    "country": "country",
    "locality": "locality",
    "region": "region",
    "postal_code": "postal_code",
    "street_address": "street_address",
    "latitude": "latitude",
    "longitude": "longitude"
  }
}